{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>lueur</p> <p>lueur is here to help you uncover and address resiliency issues early in your development cycle. By easily injecting network faults into your application\u2019s daily workflows, lueur encourages you to shift resiliency concerns to the left, long before reaching production. The result: more confident engineering teams and applications that gracefully handle the unexpected.</p> <p>At its core, lueur acts as a local proxy you can route traffic through, giving you fine-grained control over conditions like latency, jitter, and faults. Rather than waiting until late-stage testing or worse, customer reports, you can quickly see how your application responds when the network isn\u2019t perfect.</p> <p>Why lueur?</p> <ul> <li>Speed: Quickly stand up a local test environment with minimal setup.</li> <li>Simplicity: Just a few commands let you inject latency or run complex   scenarios\u2014no steep learning curve required.</li> <li>Extensibility: Tweak parameters, plug into automated tests, and integrate   with your existing CI/CD pipelines.</li> <li>Insight: Generate structured reports that help pinpoint issues and   identify ways to improve resiliency.</li> </ul> <p>Take a look at the Tutorials, How-To Guides, Explanations, and Reference sections to start exploring what lueur can do for your team.</p> <ul> <li>:fontawesome-brands-html5: HTML for content and structure</li> <li>:fontawesome-brands-js: JavaScript for interactivity</li> <li>:fontawesome-brands-css3: CSS for text running out of boxes</li> <li>:fontawesome-brands-internet-explorer: Internet Explorer ... huh?</li> </ul>"},{"location":"why-lueur/","title":"Why lueur?","text":"<p>We are building lueur because we have met unexpected production issues which forced us to scramble, patch code at the last minute, and hope that live fixes will hold up, all under pressure.</p> <p>lueur aims to change that story. It brings reliability testing right into your daily development routine, so you\u2019re not left guessing how your code will behave under tough network conditions.</p> <p>Instead of waiting until the final stretch\u2014when the impacts are higher and fixes cost more\u2014lueur invites you to explore resilience as you go. It\u2019s built to help you identify weak spots early, reducing last-minute surprises and giving you more time to craft thoughtful solutions.</p> <p>What\u2019s in it for you? Less stress. More confidence. And the freedom to improve your application\u2019s reliability before it ever reaches your customers.</p>"},{"location":"why-lueur/#features-that-work-with-you","title":"Features That Work With You","text":""},{"location":"why-lueur/#protocol-support","title":"Protocol Support","text":"<p>lueur slips into your workflow without demanding a big overhaul. Just point your traffic through its proxy and test your application as normal:</p> <ul> <li>Forward and tunnel proxy modes</li> <li>HTTP and HTTPS</li> <li>HTTP/1.1 and HTTP/2</li> <li>Scenarii automation</li> </ul>"},{"location":"why-lueur/#real-world-faults-at-your-fingertips","title":"Real-World Faults at Your Fingertips","text":"<p>lueur simulates the kinds of hiccups you\u2019ve seen (or worried about) in production\u2014right on your own machine:</p> <ul> <li>Inject HTTP errors to see if your app recovers gracefully.</li> <li>Add latency and jitter to gauge performance under slow networks.</li> <li>Test packet loss and bandwidth limits to discover scaling limits.</li> <li>Introduce random \u201cbad gateway\u201d responses and ensure robust fallback paths.</li> </ul>"},{"location":"why-lueur/#tailored-for-your-needs","title":"Tailored for Your Needs","text":"<p>If your scenario demands more than the built-in faults, lueur\u2019s gRPC interface lets you customize your own conditions. Mold the tool to fit your environment, not the other way around.</p>"},{"location":"why-lueur/#lightweight-and-fast","title":"Lightweight and Fast","text":"<p>lueur wants to help you, not slow you down. It\u2019s a single binary that starts up quickly and has minimal overhead. That means you can integrate it into your daily workflow, tests, and continuous integration pipelines without feeling weighed down.</p> <p>Under the hood, lueur uses Rust to ensure speed, safety, and resilience\u2014just like what you strive for in your own code.</p>"},{"location":"why-lueur/#the-real-world-costs-of-slowness-and-unreliability","title":"The Real-World Costs of Slowness and Unreliability","text":"<p>It\u2019s not just about feeling \u201cfast.\u201d Slow or unreliable responses can have real business and user engagement costs\u2014even during early development phases. By helping you pinpoint potential performance and reliability issues early, lueur empowers you to avoid these pitfalls:</p> <ul> <li> <p>Reduced Revenue: Amazon famously found that every 100ms increase in page   load time cost them about 1% in sales (1). Sluggish endpoints aren\u2019t just an   inconvenience; they hit the bottom line.</p> </li> <li> <p>Higher Bounce Rates: According to Google, over half of mobile users abandon   a site if it takes longer than three seconds to load (2). Users today expect speed   and smoothness from the start.</p> </li> <li> <p>Decreased Engagement and Trust: Akamai\u2019s research highlights that a two-second   delay in web page load time can cause bounce rates to skyrocket (3). Slow, error-prone   services send a message of unreliability to your users\u2014something that\u2019s hard to   rebuild once trust is lost.</p> </li> </ul> <ol> <li>Greg Linden\u2019s Slides from Amazon on the cost of latency: Marissa Mayer at Web 2.0 </li> <li>Google, The Need for Mobile Speed: How Mobile Page Speed Impacts Customer Engagement (2018)  </li> <li>Akamai, Akamai Online Retail Performance Report (2017)</li> </ol> <p>What does this mean for you? By injecting faults and testing resiliency scenarios early with lueur, you\u2019re investing in a smoother launch, happier users, healthier on-calls and a product that stands strong under real-world conditions. Instead of postponing issues discovery late\u2014when they\u2019re costlier and more stressful to fix\u2014you\u2019ll tackle them when the code is fresh and flexible.</p>"},{"location":"why-lueur/#rethinking-how-we-build-software","title":"Rethinking How We Build Software","text":"<p>Traditionally, developers focus on crafting features and fixing bugs, leaving resilience concerns to be uncovered later by SREs, performance engineers, or end users in production. lueur challenges this status quo by inviting developers to think differently\u2014early, locally, and without guesswork\u2014about the resilience of their applications. This isn\u2019t just a shift in tools; it\u2019s a shift in philosophy.</p> <p>We want to help you move beyond a mindset where reliability is an afterthought. Instead, imagine it as a first-class concern in your day-to-day coding routine, as natural as running unit tests or linting your code. By experimenting with realistic fault conditions before your application ever leaves your workstation, you\u2019re not just preventing outages\u2014you\u2019re nurturing a culture of forward-thinking and robust engineering.</p>"},{"location":"why-lueur/#new-indicators-of-reliability","title":"New Indicators of Reliability","text":"<p>How can we talk about reliability in a way that resonates with developers? We propose a set of new indicators that highlight different angles of resilience:</p> <ul> <li> <p>Latency Tolerance: How gracefully does your application handle slow   network responses? Identifying how long it can wait before timing out or   degrading service helps you set meaningful SLOs (Service Level Objectives).</p> </li> <li> <p>Failure Surface Awareness: By injecting HTTP errors, packet loss, or   bandwidth constraints, you gain clarity on where your code is most fragile.   Measuring how many parts of your service break under each condition provides   a new perspective on your \u201cfailure surface.\u201d</p> </li> <li> <p>Retry Overhead: Discover the hidden costs of your application\u2019s recovery   strategies. Do you retry too aggressively, wasting resources and time?   Tracking how your code responds to fault scenarios reveals whether your   fallback paths are efficient or need fine-tuning.</p> </li> <li> <p>Resilience Debt: Like technical debt, resilience debt accumulates when you   postpone reliability fixes. Early detection and quantification of this debt   helps prioritize improvements before they become expensive production   firefights.</p> </li> </ul>"},{"location":"why-lueur/#a-daily-practice-not-a-crisis-response","title":"A Daily Practice, Not a Crisis Response","text":"<p>Think of lueur as a steady practice in your development cadence. Just as TDD (Test-Driven Development) encourages writing tests first, we envision a Reliability-First Development approach: write a feature, inject a fault, and see how it holds up. Adjust, refine, and proceed with a clearer understanding of how your software behaves under stress.</p> <p>This shift in mindset encourages you to proactively craft solutions that don\u2019t just work in ideal conditions\u2014they thrive in real-world, sometimes messy, environments. Over time, this practice becomes muscle memory, and resilience testing transforms from an occasional chore into an integral part of building software that users trust.</p> <p>lueur isn\u2019t just another tool on your belt; it\u2019s a new way of thinking about and measuring reliability. We\u2019re here to help you see beyond happy paths, to embrace uncertainty early, and to raise the bar on what \u201cdone\u201d really means.</p> <p>lueur is about making your life easier when it comes to building reliable software. It puts you in the driver\u2019s seat, letting you explore and solidify the resilience of your applications before those big, stressful moments can occur.</p>"},{"location":"tutorials/getting-started/","title":"Getting Started with lueur","text":"<p>Welcome to lueur\u2014your new ally in exploring and understanding the impact of these petty network issues on your application! In this brief tutorial, we\u2019ll help you get up and running with lueur so that you can start experimenting with network faults and latency right from your own environment.</p> <p>By the end of this tutorial, you\u2019ll have:</p> <ul> <li>Installed lueur on your machine.</li> <li>Started a local proxy to simulate network conditions.</li> <li>Started a local demo application for learning purpose</li> <li>Made your first request through the proxy, observing how latency affects the   application.</li> </ul> <p>Let\u2019s get started!</p>"},{"location":"tutorials/getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before diving in, make sure you have the following:</p> <ul> <li>A supported operating system: lueur runs smoothly on most modern Linux,   macOS, and Windows systems.</li> </ul>"},{"location":"tutorials/getting-started/#step-1-installation","title":"Step 1: Installation","text":"<p>If you haven\u2019t installed lueur yet, here\u2019s a quick way to do it:</p> <ol> <li>Head over to the lueur Releases page    and download the binary for your platform.  </li> <li>Extract the binary and place it in a directory included in your <code>$PATH</code>    (like <code>/usr/local/bin</code> on Linux/macOS or in a PATH-enabled directory on    Windows).</li> </ol>"},{"location":"tutorials/getting-started/#step-2-starting-the-local-proxy","title":"Step 2: Starting the Local Proxy","text":"<p>lueur operates by running a local proxy server. You can route your application\u2019s traffic through it to simulate network faults. Let\u2019s start a simple latency scenario:</p> <pre><code>lueur run --upstream http://localhost:7070 latency --mean 300\n</code></pre> <p>For all latency options, use:</p> <pre><code>lueur run latency --help\n</code></pre> <p>This command launches the lueur proxy on a local port (by default, <code>127.0.0.1:8080</code>) and injects an average of <code>300ms</code> latency into outgoing requests. You can adjust the <code>--mean</code> value to experiment with different latencies.</p> <p>Failure</p> <p>Note, if you see an error with a mesage such as <code>Os { code: 98, kind: AddrInUse, message: \"Address already in use\" }</code>, it is a signe that another process is listening on the same address.</p> <p>The <code>--upstream http://localhost:7070</code> argument tells lueur to only process traffic from and to this host.</p> <p>Tip</p> <p>Always remember to set the right upstream server address that matches the endpoints you are exploring. You can set many <code>--upstream</code> arguments.</p> <p>Any traffic received by lueur that does not match any of these upstream addresses will go through the proxy unaltered.</p> <p>Once started, the proxy should issue the following message:</p> <pre><code>Welcome to lueur \u2014 Your Resiliency Exploration Tool!\n\nTo get started, route your HTTP/HTTPS requests through:\nhttp://127.0.0.1:8080\n\nAs you send requests, lueur will simulate network conditions\nso you can see how your application copes.\n\nReady when you are \u2014 go ahead and make some requests!\n</code></pre> <p>Notice how the output tells you the address of the proxy server to use from your clients.</p> <p>You are now ready to roll!</p>"},{"location":"tutorials/getting-started/#step-3-starting-a-demo-application","title":"Step 3: Starting a demo application","text":"<p>For the purpose of this tutorial, we will use a demo application built-in into lueur.</p> <p>Start the demo application in a different terminal:</p> <pre><code>lueur demo run\n</code></pre> <p>This will start an application and listen for HTTP requests on <code>http://localhost:7070</code>.</p> <p>This will output the following prelude:</p> <pre><code>Welcome to lueur, this demo application is here to let you explore lueur's capabilities.\n\nHere are a few examples:\n\nexport HTTP_PROXY=http://localhost:8080\nexport HTTPS_PROXY=http://localhost:8080\n\ncurl -x ${HTTP_PROXY} http://127.0.0.1:7070/\ncurl -x ${HTTP_PROXY} http://127.0.0.1:7070/ping\ncurl -x ${HTTP_PROXY} http://127.0.0.1:7070/ping/myself\ncurl -x ${HTTP_PROXY} --json '{\"content\": \"hello\"}' http://127.0.0.1:7070/uppercase\n</code></pre> <p>The demo describes which endpoints are available and how to call them.</p> <p>First, you can verify the demo is running correctly with <code>curl</code>:</p> <pre><code>curl http://localhost:7070\n</code></pre> <p>which should output:</p> <pre><code>&lt;h1&gt;Hello, World!&lt;/h1&gt;\n</code></pre> <p>Look at the demo application output and you should see the request was served:</p> <pre><code>GET / 200 6.627\u00b5s\n</code></pre> <p>The given timing <code>6.627\u00b5s</code> represents the duration of the request/response processing by the demo application for that particular request.</p> <p>Let's now enrich the <code>curl</code> command above to output the time taken from the client's perspective:</p> <pre><code>curl \\\n  -o /dev/null -s -w '{\"total_time\": %{time_total}}\\n' \\\n  http://localhost:7070/\n</code></pre> <p>This should display something such as:</p> <pre><code>{\"total_time\": 0.000544}\n</code></pre> <p>The time is displayed in seconds. Here the response took <code>544\u00b5s</code>.</p> <p>Let's now move to the next stage, inducing latency impacting the client's point of view of the time taken to receive a response from the demo application.</p>"},{"location":"tutorials/getting-started/#step-4-configuring-your-application-to-use-the-proxy","title":"Step 4: Configuring Your Application to Use the Proxy","text":"<p>Now that lueur\u2019s running, configure your application\u2019s HTTP requests to pass through the proxy.</p> <p>For example, if you\u2019re using <code>curl</code>, you might do:</p> <pre><code>curl -o /dev/null -s -w '{\"total_time\": %{time_total}}\\n' \\\n  -x http://127.0.0.1:8080 \\\n  http://localhost:7070\n</code></pre> <p>With <code>-x http://127.0.0.1:8080</code> set, all requests made via <code>curl</code> will flow through lueur, experiencing the specified latency. By observing your application\u2019s behavior (whether it\u2019s a command-line tool, a local service, or a browser hitting a test endpoint), you\u2019ll gain first-hand insight into how network slowdowns affect it.</p> <p>Tip</p> <p>Most of the time, you can set either the <code>HTTP_PROXY</code> or <code>HTTPS_PROXY</code> environment variables to let your client know it needs to go through a proxy: <code>export HTTP_PROXY=http://127.0.0.1:8080</code>.</p> <p>Once you have executed that command, you should see a much higher response time:</p> <pre><code>{\"total_time\": 0.339949}\n</code></pre> <p>We are now above the <code>300ms</code> mark as per the configuration of our proxy.</p> <p>Fantastic, you have now succeeded in altering the perception your clients would have from your using your application. The only question remaining is whether or not this is a level that is acceptable by the organisation.</p>"},{"location":"tutorials/getting-started/#step-5-observing-the-effects","title":"Step 5: Observing the Effects","text":"<p>Trigger a few requests from your application. Notice how responses now arrive slightly delayed. This delay simulates real-world network conditions\u2014exactly what lueur is here to help you understand and address.</p> <ul> <li>If your application times out or behaves strangely under these conditions,   you\u2019ve just uncovered a resilience gap.</li> <li>If it gracefully handles delayed responses, congratulations! Your software   is a step closer to being truly reliable.</li> </ul>"},{"location":"tutorials/getting-started/#next-steps","title":"Next Steps","text":"<p>You\u2019ve successfully set up lueur, run your first latency scenario, and routed traffic through it. What\u2019s next?</p> <ul> <li>Try different latency values or other fault injection parameters to get   a feel for how your application responds to varied conditions.</li> <li>Explore our Tutorials further to learn how to simulate scenarios   using <code>.toml</code> files and generate detailed reports.</li> <li>Dive into How-To Guides to integrate lueur deeper into   your workflow, from automated testing to continuous integration.</li> </ul> <p>With this initial setup under your belt, you\u2019re well on your way to embracing a culture of resilience in your everyday development tasks. Happy experimenting!</p>"},{"location":"tutorials/install/","title":"Install lueur","text":"<p>lueur strives to get of your way and it starts with a smooth installation.</p>"},{"location":"tutorials/install/#download-lueur","title":"Download lueur","text":"<p>lueur is provided as a binary targetting the three major platforms: Linux, macOS and Windows.</p> <p>You can download the appropriate binary for your platform from here.</p> <p>Once you have downloaded the archive, you can uncompress it and make sure it can be found in your <code>PATH</code>.</p> Linux, macOS, Windows BashWindows Powershell <pre><code>export PATH=$PATH:`pwd`\n</code></pre> <pre><code>$env:Path += ';C:\\directoy\\where\\lueur\\lives' \n</code></pre> <p>Tip</p> <p>On Linux and macOS you will need to make sure the binary gets the executable permission flipped on with:</p> <pre><code>chmod a+x lueur\n</code></pre>"},{"location":"tutorials/install/#check-lueur-is-ready-to-roll","title":"Check lueur is ready to roll","text":"<p>Let's verify it all went well by running the following command:</p> <pre><code>lueur --help\n</code></pre> <p>This should output the following:</p> <pre><code>A proxy to test network resilience by injecting various faults.\n\nUsage: lueur [OPTIONS] &lt;COMMAND&gt;\n\nCommands:\n  run       Apply a network fault\n  scenario  Execute a predefined scenario\n  demo      Run a simple demo server for learning purpose\n  help      Print this message or the help of the given subcommand(s)\n\nOptions:\n      --log-file &lt;LOG_FILE&gt;    Path to the log file. Disabled by default\n      --log-stdout             Stdout logging enabled\n      --log-level &lt;LOG_LEVEL&gt;  Log level [default: info,tower_http=debug]\n  -h, --help                   Print help\n  -V, --version                Print version\n</code></pre>"},{"location":"tutorials/install/#troubleshooting","title":"Troubleshooting","text":"<p>If you receive a message such as \u0300<code>lueur: No such file or directory</code>, it likely means you have not put the directory containing the <code>lueur</code> binary in your  <code>PATH</code>, or you may need to restart your session for the changes to take effect.</p>"},{"location":"tutorials/install/#next-steps","title":"Next Steps","text":"<p>You\u2019ve successfully downloaded and made lueure. What\u2019s next?</p> <ul> <li>Explore our Getting Started Tutorial to learn how to first use lueur.</li> <li>Dive into How-To Guides to integrate lueur deeper into   your workflow, from automated testing to continuous integration.</li> </ul>"},{"location":"tutorials/real-impact-use-case/","title":"Exploring Network Fault Impact","text":""},{"location":"tutorials/real-impact-use-case/#introduction","title":"Introduction","text":"<p>Context:   Introduce the idea that modern applications often rely on third-party APIs over HTTPS.   Explain that this tutorial will walk the reader through simulating various network faults using Lueur to understand how their own application behaves under non-ideal conditions.</p> <p>Goal:   By the end of this tutorial, the reader will:   - Configure Lueur to apply multiple types of faults (latency, errors, bandwidth limits) to an outbound HTTPS call.   - Run a defined scenario that systematically applies these faults.   - Observe the application\u2019s behavior and interpret the resulting report.</p>"},{"location":"tutorials/real-impact-use-case/#prerequisites","title":"Prerequisites","text":"<p>Tools &amp; Setup:</p> <ul> <li>Lueur installed on your local machine.</li> <li>An existing application or a simple test client that makes HTTPS calls to a known third-party endpoint (e.g., <code>https://api.example.com</code>).</li> <li>Basic familiarity with setting <code>HTTP_PROXY</code> or <code>HTTPS_PROXY</code> environment variables.</li> </ul> <p>Assumptions:   The tutorial assumes the reader has followed the Getting Started tutorial and understands how to launch Lueur in basic mode.</p>"},{"location":"tutorials/real-impact-use-case/#step-1-choosing-the-third-party-endpoint","title":"Step 1: Choosing the Third-Party Endpoint","text":"<ul> <li>Explain how to pick a stable third-party endpoint (e.g., a public API or a test endpoint) for demonstration.  </li> <li>Suggest <code>https://api.example.com</code> as a placeholder.  </li> <li>Verify the application makes a simple GET request to this endpoint under normal conditions.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#step-2-creating-a-scenario-file","title":"Step 2: Creating a Scenario File","text":"<ul> <li>Introduce the scenario file (<code>scenario.toml</code>) and explain its purpose in defining multiple, sequential tests.  </li> <li>Provide a sample <code>scenario.toml</code> snippet that includes a variety of faults:</li> <li>A run with added latency (e.g., 300ms mean).</li> <li>A run that simulates packet loss (e.g., 2%).</li> <li>A run that injects occasional 500 errors.</li> <li> <p>A run that limits bandwidth to a low rate.</p> </li> <li> <p>Show how to write these steps in a way that Lueur\u2019s scenario runner can understand.</p> </li> </ul>"},{"location":"tutorials/real-impact-use-case/#step-3-configuring-your-application-and-environment","title":"Step 3: Configuring Your Application and Environment","text":"<ul> <li>Instruct setting <code>HTTPS_PROXY</code> to <code>http://127.0.0.1:8080</code> so all outbound HTTPS calls route through Lueur.</li> <li>Confirm that your application still functions normally without faults before running the scenario.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#step-4-running-the-scenario","title":"Step 4: Running the Scenario","text":"<ul> <li>Demonstrate the command:   <pre><code>lueur scenario run --scenario scenario.toml --report scenario-report.json\n</code></pre></li> <li>Explain what Lueur is doing: it launches a proxy, applies each set of defined faults in sequence, and captures metrics and logs.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#step-5-observing-logs-and-output","title":"Step 5: Observing Logs and Output","text":"<ul> <li>Show how Lueur\u2019s console output reports requests, injected faults, and response times.</li> <li>Emphasize what to look for:</li> <li>Increased latency in responses.</li> <li>Occasional HTTP 500 errors injected by the scenario.</li> <li>Impact of packet loss or bandwidth constraints on perceived throughput.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#step-6-analyzing-the-generated-report","title":"Step 6: Analyzing the Generated Report","text":"<ul> <li>Introduce the <code>scenario-report.json</code> file:</li> <li>Show how to open it and what data to look for.</li> <li>Highlight metrics like total request counts, success vs. error rates, average latency, and other relevant stats.</li> <li>Discuss interpreting this data to identify how resilient the application is to each type of fault.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#step-7-identifying-areas-for-improvement","title":"Step 7: Identifying Areas for Improvement","text":"<ul> <li>Encourage the reader to reflect on what they\u2019ve observed:</li> <li>Did the application handle latency gracefully, or did requests time out?</li> <li>Did error handling and retries come into play when faced with injected 500 errors?</li> <li> <p>How did the application behave when bandwidth was limited?</p> </li> <li> <p>Suggest actionable improvements:</p> </li> <li>Consider adding retry logic or timeouts.</li> <li>Improve error handling to degrade gracefully when encountering random faults.</li> <li>Optimize for slower networks if necessary.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#next-steps","title":"Next Steps","text":"<ul> <li>Point to other How-To guides for fine-tuning scenarios or integrating Lueur into CI pipelines.</li> <li>Suggest expanding the scenario file with more complex tests or different endpoints.</li> <li>Encourage experimenting with different fault profiles to continuously challenge and improve the application\u2019s resilience.</li> </ul>"},{"location":"tutorials/real-impact-use-case/#conclusion","title":"Conclusion","text":"<ul> <li>Summarize what was achieved:</li> <li>The reader learned how to define and run a scenario that simulates multiple network faults on a real HTTPS call.</li> <li> <p>They observed how their application responded under stressed conditions and gathered data to guide improvements.</p> </li> <li> <p>Reinforce that this practice helps catch issues earlier, ensuring a smoother path to production.</p> </li> </ul>"}]}